{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Trabajo Práctico 1: Reservas de Hotel**\n",
    "## Checkpoint 2\n",
    "**Grupo 35**\n",
    "\n",
    "Integrantes:\n",
    "- Aylas, Brenda\n",
    "- Cori, William\n",
    "- Nazario, Ingrith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import BinaryEncoder, OneHotEncoder\n",
    "from datetime import datetime\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Cargo el dataset de train procesado en el primer checkpoint y lo separo en X e Y.\n",
    "Tambien cargo el dataset de test y separo los ids para unirlos luego a los valores que prediga el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_train = pd.read_csv(\"../data/hotels_processed.csv\")\n",
    "\n",
    "x_train = hotels_train.drop(\"is_canceled\", axis=1)\n",
    "y_train = hotels_train.filter([\"is_canceled\"])\n",
    "\n",
    "x_test = pd.read_csv(\"../data/hotels_test.csv\")\n",
    "ids_test = x_test.loc[:,\"id\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de pipeline\n",
    "\n",
    "Armo un pipeline en el que utilizo one hot encoding para las columnas categóricas con pocas categorias distintas, utilizo binary enconding para las columnas con muchas categorias distintas (>12) para no generar una excesiva cantidad de columnas y descarto las columnas que se decidio elimnar en el primer checkpoint o son prohibidas para este trabajo practico. El modelo utilizado es DecisionTreeClassifier de Scikitlearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder_cols = [\n",
    "  'hotel',\n",
    "  'arrival_date_month',\n",
    "  'meal',\n",
    "  'market_segment',\n",
    "  'distribution_channel',\n",
    "  'reserved_room_type',\n",
    "  'assigned_room_type',\n",
    "  'deposit_type',\n",
    "  'customer_type',\n",
    "  'is_repeated_guest'\n",
    "]\n",
    "\n",
    "binary_encoder_cols = [\n",
    "  'country',\n",
    "  'agent'\n",
    "]\n",
    "\n",
    "ignored_cols = [\n",
    "  \"reservation_status_date\",\n",
    "  \"id\",\n",
    "  \"company\",\n",
    "]\n",
    "\n",
    "def drop_colums(X: pd.DataFrame):\n",
    "  return [col for col in X.columns if col in ignored_cols]\n",
    "\n",
    "column_trans = ColumnTransformer(\n",
    "  transformers=(\n",
    "    (\"binary_encoder\", BinaryEncoder(cols=binary_encoder_cols), binary_encoder_cols),\n",
    "    (\"one_hot_encoder\", OneHotEncoder(cols=one_hot_encoder_cols), one_hot_encoder_cols),\n",
    "    (\"drop\", \"drop\", drop_colums)\n",
    "  ),\n",
    "  remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "  steps=[\n",
    "    (\"transformer\", column_trans),\n",
    "    (\"model\", DecisionTreeClassifier())\n",
    "  ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busqueda de hiperparametros\n",
    "\n",
    "Utilizo GridSearchCV de scikitlearn para probar distintos valores de hiperparametros. Para ejecutarlo hay que setear el boolean en la celda(Tiempo de ejecucion aproximado: 20min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'model__criterion':['gini', 'entropy'],\n",
    "  'model__min_samples_leaf':[3, 5, 10, 15, 20, 25],\n",
    "  'model__ccp_alpha':np.linspace(0,0.05, 20),\n",
    "  'model__max_depth':list(range(20, 51, 5))\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "  estimator=pipeline,\n",
    "  param_grid=params,\n",
    "  scoring=\"f1\",\n",
    "  n_jobs=-1,\n",
    "  cv=5\n",
    ")\n",
    "\n",
    "grid_search_enable = False\n",
    "if grid_search_enable:\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  print(f\"Best params: {grid_search.best_params_}\")\n",
    "  print(f\"F1 score: {grid_search.best_score_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entreno el modelo con los hiperparametros finales, lo uso con el dataset de test y armo la prediccion a presentar en kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_ if grid_search_enable else {'model__ccp_alpha': 0.0, 'model__criterion': 'entropy', 'model__max_depth': 20, 'model__min_samples_leaf': 15}\n",
    "pipeline.set_params(**best_params)\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "y_predict = pipeline.predict(x_test)\n",
    "result = pd.DataFrame({\"id\": ids_test, \"is_canceled\": y_predict})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardo el modelo y el resultado a presentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \"../tmp\"\n",
    "Path(tmp).mkdir(exist_ok=True)\n",
    "now = datetime.now().strftime(\"%Y_%m_%dd_%H_%M_%S\")\n",
    "\n",
    "result.to_csv(f\"{tmp}/result_{now}.csv\")\n",
    "with open(f\"{tmp}/decision_tree_classifier_{now}\", \"wb\") as fh:\n",
    "  dill.dump(pipeline, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
